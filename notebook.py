# -*- coding: utf-8 -*-
"""notebook.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1J8311i1i9e-8Adqdj4UtSzYDsFITwdf_

# Data Scientist Associate Practical Exam Submission

-In the first task I checked whether all columns match the description given. I corrected the ones that did not match. I completed the missing data
-I made the necessary visualizations in the second, third and fourth task
-in the fifth task I indicated which type of machine learning problem it is.( it is classification problem)
-in the sixth task I split the data into train and test and used the fit model for the baseline model.(Logistic Regression)
-in the seventh task I split the data into train and test and used the fit model for the comparison model.(Random Forest Classifier)
-in the eighth task I explained why I chose logistic regression and random forest classifier
-in the ninth task I calculated the accuracy of two models
-in the tenth task I indicated which model performs better
"""

#Importing the needed libraries for the analysis
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
# Loading data into DataFrame
df=pd.read_csv("fitness_class_2212.csv")
df.head()

#overviewing the data
print(df.info())
print("----------------------")
print(df.describe())

"""## Task 1
 **For every column in the data: a. State whether the values match the description given in the table above**
"""

#FIRST I will check "booking_id"
#Nominal. The unique identifier of the booking.
# Let's check the data type of the column
data_type = df['booking_id'].dtype
print(data_type)

if (data_type == 'object' or data_type.name == 'category'):
    print("'booking_id' column is nominal .")
else:
    print("'booking_id' column is not nominal.")

#it is nominal

##SECOND I will check "months_as_member"
##Discrete. The number of months as this fitness club member

# Lets check dtypes in the column
data_type = df["months_as_member"].dtype
print(data_type)
if data_type == 'int64':
    print("months_as_member is discrete column.")
else:
    print("months_as_member is not discrete column.")

#months_as_member is  discrete column
#----------------
#minimum 1 month
print(df["months_as_member"].min())
#1 month is true

##THIRD I will check "weight"
##Continuous.

# Let's check the data type and value range of the column
data_type = df['weight'].dtype
value_range = df['weight'].max() - df['weight'].min()

if data_type == 'float64' and value_range > 0:
    print("'weight' column is Continuous  column.")
else:
    print("'weight' column is not Continuous  column.")
#Yes "weight" column is Continous column

#----------
##The member's weight in kg, rounded to 2 decimal
##places. The minimum possible value is 40.00 kg.
print(df["weight"].min()) #55.41

#min value is not under 40.00 kg and values rounded to 2 decimal. Its true

##FOURTH I will check "days_before"
##Discrete.

# Lets check dtypes  in the column

data_type = df["days_before"].dtype
print(data_type)

if  data_type == 'int64' or data_type == "float64":
    print("days_before is discrete column.")
else:
    print("days_before is not discrete column.")

#days_before is not discrete column.Because dtype is object

#------
##The number of days before the class the member
##registered, minimum 1 day.
print(df["days_before"].min())

#min number =1 . Its true

##FIFTH I will check "day_of_week"
##Nominal.

# Let's check the data type of the column
data_type = df['day_of_week'].dtype

# Let's check the number of unique values of the column
unique_values = df['day_of_week'].nunique()

if (data_type == 'object' or data_type.name == 'category') and unique_values <= 10 :
    print("'day_of_week' column is nominal .")
else:
    print("'day_of_week' column is not nominal.")

#it is nominal

#-----

##The day of the week of the class. One of “Mon”, “Tue”,
##“Wed”, “Thu”, “Fri”, “Sat” or “Sun”.
print(df["day_of_week"].unique())
#day_of_column also contains "fri.","Wednesday","Monday"

##SIXTH I will check "time"
##Ordinal.

# Let's check the data type of the column
data_type = df['time'].dtype
print(data_type)

if (data_type == 'object' or data_type.name == 'category'):
    print("'time' column is ordinal.")
else:
    print("'time' column is not ordinal.")

# Its not ordinal

#------------

##The time of day of the class. Either “AM” or “PM”.
df["time"].unique()
print(df["time"].value_counts())

##SEVENTH I will check "category"
##Nominal.

# Let's check the data type of the column
data_type = df['category'].dtype

# Let's check the number of unique values of the column
unique_values = df['category'].nunique()

# Let's check if there is a sequence(sorting)
is_ordered = df['category'].is_monotonic

if (data_type == 'object' or data_type.name == 'category') and unique_values <= 10 and not is_ordered:
    print("'category' column is nominal .")
else:
    print("'category' column is not nominal.")

#Its nominal

##The category of the fitness class. One of “Yoga”, “Aqua”,
##“Strength”, “HIIT”, or “Cycling”

df["category"].unique()
#category column also contains "-"

##EIGTH I will check "attended"
##Nominal.

# Let's check the data type of the column
data_type = df['attended'].dtype
print(data_type)

# Let's check the number of unique values of the column
unique_values = df['attended'].nunique()


if (data_type == 'object' or data_type.name == 'category') and unique_values <= 10 :
    print("'attended' column is nominal .")
else:
    print("'attended' column is not nominal.")


#Its not nominal

#-------

##Whether the member attended the class (1) or not (0)

print(df["attended"].unique())

"""**b. State the number of missing values in the column**"""

# Count the number of missing values in each column
missing_values_count = df.isnull().sum()

# Print the number of missing values for each column
print(missing_values_count)

"""**c. Describe what you did to make values match the description if they did not match.**"""

#FIRST I will fix "booking_id"."booking_id is not nominal.Convert this column to nominal"
df['booking_id'] = df['booking_id'].astype('category')

# Let's check the data type of the column
data_type = df['booking_id'].dtype

if (data_type == 'object' or data_type.name == 'category') :
    print("'booking_id' column is nominal .")
else:
    print("'booking_id' column is not nominal.")

#No missing values

#SECOND I will fix "months_as_member

#All informations true
print("----------")
#Replace missing values with the overall average month.
overall_average = df['months_as_member'].mean()
df['months_as_member'].fillna(overall_average,inplace=True)
print(df['months_as_member'])

#THIRD I will fix "weight"
#All informations are true
print("----------")
#Replace missing values with the overall average weight.
overall_average = df['weight'].mean()
print("overall average: ",overall_average)
rounded_overall_average=round(overall_average,2)
print("rounded overal average :",rounded_overall_average)
df['weight'].fillna(rounded_overall_average,inplace=True)
print(df["weight"])
print(df["weight"].unique())

#FOURTH I will fix "days_before"."days_before is not discrete.Convert this column to discrete"
#we are getting this error -->invalid literal for int() with base 10: '12 days'. to fix
df['days_before'] = df['days_before'].str.replace(" days", "")
df["days_before"] = df["days_before"].astype(int)

# Let's check the data type of the column
data_type = df['days_before'].dtype
print(data_type)

if  data_type == 'int64' or data_type == "float64":
    print("days_before is discrete column.")
else:
    print("days_before is not discrete column.")

#Replace missing values with 0.
df['days_before'].fillna(0, inplace=True)
print(df["days_before"].unique())

#FIFTH I will fix "day_of_week"
## Its Nominal, true

## BUT
##The day of the week of the class. One of “Mon”, “Tue”,
##“Wed”, “Thu”, “Fri”, “Sat” or “Sun”.
print(df["day_of_week"].unique())
#day_of_column also contains "fri.","Wednesday","Monday"
##Lets fix
df['day_of_week'] = df['day_of_week'].replace('Fri.', 'Fri')
df['day_of_week'] = df['day_of_week'].replace('Wednesday', 'Wed')
df['day_of_week'] = df['day_of_week'].replace('Monday', 'Mon')
##Lets checkh
##The day of the week of the class. One of “Mon”, “Tue”,
##“Wed”, “Thu”, “Fri”, “Sat” or “Sun”.
print(df["day_of_week"].unique())

#SIXTH I will fix "time"
###All informations are true
print("----------")
#Replace missing values with “unknown”.
df['time'].fillna('unknown', inplace=True)
print(df["time"].isna().sum())
print(df["time"].unique())

#SEVENTH I will fix "category"
## Its Nominal true
print("------------")

##The category of the fitness class. One of “Yoga”, “Aqua”,
##“Strength”, “HIIT”, or “Cycling”

print(df["category"].unique())
#category column also contains "-"
#lets drop "-"
df = df[df['category'] != '-']
print(df["category"].unique())

#Replace missing values with “unknown”.
df['category'].fillna('unknown', inplace=True)
print(df["category"].isna().sum())

#EIGHTH I will fix "attended" column. "attended is not nominal.Convert this column to nominal"
df['attended'] = df['attended'].astype('category')

# Let's check the data type of the column
data_type = df['attended'].dtype

if (data_type == 'object' or data_type.name == 'category') :
    print("'attended' column is nominal .")
else:
    print("'attended' column is not nominal.")

##Missing values should be removed.
df.dropna(subset=['attended'], inplace=True)
print(df["attended"].unique())

# Count the number of missing values in each column again
missing_values_count = df.isnull().sum()

# Print the number of missing values for each column again
print(missing_values_count)

df.dtypes

"""## Task 2
***Create a visualization that shows how many bookings attended the class. Use the visualization to:***

**a) state which category of the variable attended has the most observations b) Explain whether the observations are balanced across categories of the variable attended**
"""

import matplotlib.pyplot as plt

import seaborn as sns
import matplotlib.pyplot as plt

# Create a count plot
sns.countplot(data=df, x='category', hue='attended')
plt.title("Attendance by Category")
plt.xlabel("Category")
plt.ylabel("Number of Bookings")
plt.legend(title="Attended", labels=["Not Attended", "Attended"])

# Show the plot
plt.show()

"""a. Category with the Most Observations: In the count plot "HIIT" has the most observation. Because "HIIT" with the tallest combined bar (attending + not attending)

b) Explain whether the observations are balanced across categories of the variable attended: To determine if the observations are balanced, I compare the heights of the "Attended" and "Not Attended" bars within each category.Heights of the bars are relatively similar across categories, the observations are balanced.

**TASK3
Describe the distribution of the number of months as a member. Your answer must include a visualization that shows the distribution.**
"""

df.columns
print(df["months_as_member"])

print(df["months_as_member"].value_counts().max())
print(df["months_as_member"].value_counts().min())

plt.figure(figsize=(10, 6))
ax=df["months_as_member"].value_counts().plot(kind="bar",)
ax.set_xlabel("Months as Member")
ax.set_ylabel("Frequency")
ax.set_title("distribution of the enrollment counts")
plt.show()

"""## Task 4
**Describe the relationship between attendance and number of months as a member. Your answer must include a visualization to demonstrate the relationship.**
"""

df.columns

types=df.attended.unique()
for type in types:
    df.loc[df["attended"]==type,"months_as_member"].hist(bins=20,alpha=0.3,label=type)
plt.title('Distribution of the attended field across the months_as_member')
plt.show()

mean_and_median=df.groupby('attended')['months_as_member'].agg(func={np.median, np.mean})
mean_and_median.plot(kind='bar')
plt.title('Mean and Median for attended')
plt.xlabel('Attended')

df[['months_as_member', 'attended']].boxplot(column='months_as_member', by='attended', grid=False)
plt.suptitle('Boxplot of months_as_member by attended ')
plt.xlabel('attended')
plt.title('')

import matplotlib.pyplot as plt

# Create a scatter plot
plt.figure(figsize=(10, 6))
plt.scatter(df['months_as_member'], df['attended'], alpha=0.5)
plt.title("Relationship between Attendance and Number of Months as a Member")
plt.xlabel("Number of Months as a Member")
plt.ylabel("Attendance (0 = Not Attended, 1 = Attended)")
plt.xticks(rotation=45)
plt.show()

!pip install pingouin
import pingouin
alpha = 0.05
pingouin.kruskal(data=df, dv='months_as_member', between='attended')

"""According to the Kruskal-Wallis test; p value is quite low (6.992405047e-87).Which shows that there is a statistically significant relationship between the variables.

**TASK 5
The business wants to predict whether members will attend using the data provided. State the type of machine learning problem that this is (regression/ classification/ clustering).**

The problem of predicting whether members will attend using the provided data is a classification problem. In classification, the goal is to categorize input data into predefined classes or labels. In this case, the classes are "attended" (1) and "not attended" (0), making it a binary classification problem

## Task 6
**Fit a baseline model to predict whether members will attend using the data provided. You must include your code.**
"""

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score


# before fitting the baseline model, I'll use the get_dummies() method to encode categorical columns "day_of_week," "time," and "category." Then, I'll proceed with fitting a logistic regression model.

# Encode categorical columns using get_dummies
encoded_df = pd.get_dummies(df, columns=['day_of_week', 'time', 'category'], drop_first=True)

# Split the data into features (X) and target (y)
X = encoded_df.drop(columns=['booking_id', 'attended'])
y = encoded_df['attended']

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Initialize the logistic regression model
model = LogisticRegression()

# Fit the model to the training data
model.fit(X_train, y_train)

# Predict on the test data
y_pred = model.predict(X_test)

# Calculate the accuracy of the model
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy of the baseline model: {accuracy:.2f}")

"""## Task 7
**Fit a comparison model to predict whether members will attend using the data provided. You must include your code.**
"""

#Fitting a comparison model using a Random Forest classifier, which is a more complex model compared to the baseline logistic regression
from sklearn.ensemble import RandomForestClassifier

# Encode categorical columns using get_dummies
encoded_df = pd.get_dummies(df, columns=['day_of_week', 'time', 'category'], drop_first=True)

# Split the data into features (X) and target (y)
X = encoded_df.drop(columns=['booking_id', 'attended'])
y = encoded_df['attended']

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Initialize the Random Forest model
model = RandomForestClassifier(random_state=42)

# Fit the model to the training data
model.fit(X_train, y_train)

# Predict on the test data
y_pred = model.predict(X_test)

# Calculate the accuracy of the model
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy of the comparison model: {accuracy:.2f}")

"""## Task 8
**Explain why you chose the two models used in parts 6 and 7**

The choice of using both the Logistic Regression model and the Random Forest Classifier is based on their individual strengths and suitability for the given problem. -I used Logistic Regression because , the problem involves predicting attendance (binary classification), logistic regression is a natural choice. It models the probability of an instance belonging to a particular class, which aligns well with our prediction task. -And I used Random Forest classifier because Random Forest classifier is capable of capturing complex non-linear relationships between features and the target variable. This is valuable when there might be intricate interactions or patterns in the data that a linear model like logistic regression might not capture effectively.

## Task 9
**Compare the performance of the two models used in parts 6 and 7, using any method suitable. You must include your code.**
"""

# Encode categorical columns using get_dummies
encoded_df = pd.get_dummies(df, columns=['day_of_week', 'time', 'category'], drop_first=True)

# Split the data into features (X) and target (y)
X = encoded_df.drop(columns=['booking_id', 'attended'])
y = encoded_df['attended']

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Initialize and fit the Logistic Regression model
logistic_model = LogisticRegression()
logistic_model.fit(X_train, y_train)

# Initialize and fit the Random Forest Classifier model
rf_model = RandomForestClassifier(random_state=42)
rf_model.fit(X_train, y_train)

# Predict on the test data using both models
logistic_predictions = logistic_model.predict(X_test)
rf_predictions = rf_model.predict(X_test)

# Calculate accuracy for both models
logistic_accuracy = accuracy_score(y_test, logistic_predictions)
rf_accuracy = accuracy_score(y_test, rf_predictions)

# Print the accuracy of both models
print(f"Accuracy of Logistic Regression model: {logistic_accuracy:.2f}")
print(f"Accuracy of Random Forest Classifier model: {rf_accuracy:.2f}")

"""## Task 10
**Explain which model performs better and why.**

Based on the accuracy comparison, I can determine which model performs better in terms of predicting attendance.The model with a higher accuracy is generally considered better for the specific task. Accuracy of Logistic Regression model: 0.75 Accuracy of Random Forest Classifier model: 0.75 .If both models have the same accuracy score, it means that they perform similarly on the available dataset.

